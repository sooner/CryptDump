\section{related work}

1)database backup dedpulication compression

Deduplication on storage system is a hot research topic\citep{paulo2014survey}.\citep{xu2017online} proposes an online deduplication for operational database system. According to \citep{xu2017online}, dedup using hash method works well for both primary and backup storage data sets that comprises of large files that are rarely modified. In our work, we focus on archivial data, so the files are rarely modified. And those traditional method can work together with our proposed method. There are many work on deduplication for secondary storage, the can either use exact dedup\citep{dubnicki2009hydrastor} or similarity based dedup\citep{xu2015reducing} \citep{aronovich2009design}\citep{you2005deep}.

These traditional chunk based dedup system can not handled encryption well, So there are also work that address the tension between encryption and deduplication. 

Encryption and deduplication are in tension, and there are research about this issue.\citep{bellare2013message} \citep{puzio2015perfectdedup} proposed message-locked enctyption, a kind of convergent encryption to addressed this problem. \citep{yan2016deduplication} addressed the problem of deduplication of encrypted files in a multi-user situation through authorized party and token comparison, they proposed their strategy through ownership chanllenge and proxy-re-encryption. In constrast, our work forcus on generating a backup file that occupy less storage space. In fact, deduplication methods on encrypted data fall into two catagories, convergent encryption and proof of ownership\citep{akhila2016study}. Convergent encryption works like DET, So detjoin level have the potential to allow deduplication.

How to combine those two methods together to make efficient deduplication is future work.

Actually, block level comparision do not work well for database workload, so there are also research targeting database workload. 

\citep{francinasurvey} proposed three encryption schemes for deduplication, those are file level deduplication.
There are also work on solving the problem of compression and encryption\citep{zheng2017minicrypt}.

\citep{mandagere2008demystifying} says that compress tools like gzip reduce intra-file duplication while deduplication reduces both inter and intra file deduplication. It also talked about client side deduplication using metadata.

